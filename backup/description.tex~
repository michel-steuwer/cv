\documentclass[11pt,a4paper]{article}

%\moderncvtheme[blue]{classic}
\usepackage[utf8]{inputenc}
\usepackage[scale=0.8]{geometry}
%\AtBeginDocument{\recomputelengths}

%\firstname{}
%\familyname{}

\pagenumbering{gobble}

\setlength{\parskip}{.5em plus.25em minus.25em}
\setlength{\parindent}{0mm}
%----------------------------------------------------------------------------------
%            content
%----------------------------------------------------------------------------------
\begin{document}
% \begin{center}
%   \huge Project description
% \end{center}
\section{Introduction}
% Shorten a bit the first sentences ... 
% As identified by HiPEAC the increasing \textbf{complexity of systems} is one of the main challenges of computer science.
% With increasing system complexity the problem of \textbf{performance portability} arises, which is not sufficiently addressed by state-of-the-art programming models.
% Algorithmic skeletons are a promising approach to address this challenge, by providing optimized implementations specific for different hardware platforms while at the same time raising the level of abstraction for application development.
% But in a rapid changing world implementing and tuning skeleton implementations manually on every new hardware platform is still not a satisfying solution.
% 
% We will improve the current state-of-the-art by automatically generate a set of implementations of algorithmic skeletons each with different optimizations applied and then selecting the best performing one using machine learning techniques.
% Our approach will automatically adapt to new hardware architectures without the need of rewriting and manually tune implementations.
This project aims at making often recurring parallel patterns (a.k.a.
\emph{algorithmic skeletons}) performance portable on
heterogeneous platforms such as GPUs, APUs, or multicore CPUs.
We address the \textbf{complexity of systems} from two angles: 1) by simplifying
the programming providing \textbf{high-level abstraction}, and 2) by achieving
\textbf{performance portability} for optimal execution on heterogeneous systems.
In the spirit of \emph{Spiral} we want to automatically generate optimized
implementations of algorithmic skeletons.

\section{Programme}
% (1) Automatic code generation
%   - Existing high-level programming model
%     - Algorithmic skeletons (map, zip, reduce, scan, mapOverlap, allpairs)
%     - User provides customizing function
%   - Currently OpenCL source code is adjusted (modified) to make
%   customizing function and manually wirtten skeleton implementations fit using
%   clang
%   - Not portable since optimizations are bound to specific hardware platform
%   - Idea: Automatically generate different version of the skeleton
%   implementation employing the clang-based OpenCL tool chain from Edinburgh
In this project we will extend our existing high-level programming model SkelCL.
The application developer customizes an algorithmic skeleton for his application
by providing a function which is executed in parallel as defined by the semantic
of the skeleton.
For example the \emph{reduce} skeleton performs a parallel reduction of an array
to a scalar value by repetitively applying the given customizing binary function.
SkelCL currently provides six skeletons: map, zip, reduce, scan, mapOverlap and
allpairs.
SkelCL is implemented using OpenCL and currently provides manual written
implementations of the skeletons which are combined to an OpenCL kernel together
with the customizing function provided by the application developer.
The performance of the skeleton implementation is currently not portable across
devices as optimizations are done manually for a specific device architecture.
By \textbf{automatically generating different optimized versions} of the skeleton
implementation we want to explore the possible implementation design space and,
thus, generate version which perform well regardless of the target hardware
platform.
We will make use of a full OpenCL source code editing toolchain, which has
recently been developed by the CArD group at Edinburgh.

% (2) Semantic guided optimizations
%   - Exploit semantic information of skeletons for selecting optimizations
%   while the implementation remains correct
%   - Example: Memory access pattern from allpairs
%   - Example: Reduce skeleton
By using algorithmic skeletons we have \textbf{semantic information} about the
implementation available which will \textbf{guide our optimizations}.
For example the semantic knowledge how a parallel reduction can be implemented
allows us to apply more aggressive optimizations than would be possible without
these information.
As another example, when implementing the newly introduced allpairs skeleton in
SkelCL which performs computations on all pairs of vectors of two matrices (e.g.
matrix multiplication or n-body simulations) information about the memory access
pattern can be exploited to automatically utilize faster memory regions.
Other possible optimizations include: vectorization, granularity of parallelism,
loop unrolling, etc.

% (3) Select the best version
%   - In general unclear which version performs best on given hardware platform,
%   therefore, automatically select the best version using machine learning
%   techniques
%   - Extract characteristics of the implementation (and device?)
In general it is unclear which version performs best on a given hardware
platform, therefore, we will \textbf{employ machine learning techniques to
automatically select the best version}.
We will extract characteristics from the implementations and use them as
features in a machine learning model to predict the best performing
implementation. We will benefit from our previous experience in this filed (see
Dubach et. al MICRO'09).

% In this collaborative project, we want to address performance portability by automatically generating different skeleton implementations each with different optimizations applied, e.g. usage of fast local memory, vectorization, granularity of parallelism, loop unrolling, etc.
% Therefore, we will explore the design space of possible skeleton implementations and develop a tool for selecting the best performing one employing machine learning techniques, as it is in general unclear which implementation is best for an arbitrary hardware architecture.
% 
% A three month visit for this ambitious project is useful, as we can build on, extend and combine our previous research on high-level programming models based on algorithmic skeletons (see the SkelCL research project in the CV) and portable compiler optimizations (Dubach et. al MICRO’09 and Dubach et. al PLDI’12).
% For systematic generation of optimized skeleton implementations, we will use a compiler toolchain, which has recently been developed at the CArD group in Edinburgh.
% 
% The visit will stimulate the collaboration between the Universities of Edinburgh and Münster, initiating a possible long term cooperation between our research groups.
% The proposed project is highly relevant to HiPEAC and its identified cross-cutting challenges, especially the challenge of system complexity.

\section{Potential Output}
We want to directly integrate all work in the existing SkelCL library and, thereby, provide a useful contribution to research and practice.
All work performed during the project will be available as open source software, just as the SkelCL library is already.
For this three month project we will deliberately restrict ourself to develop
the required techniques for two algorithmic skeletons: reduce and allpairs.
After the three month project we will prepare a publication of our results in a
joint publication.
We target a publication at the PLDI conference (deadline November 2013).

\end{document}

